{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------\n",
      "                 Dask.distributed v2.11.0\n",
      "\n",
      "Worker nodes:\n",
      "  0: 172.26.4.115\n",
      "  1: 172.26.11.178\n",
      "  2: 172.26.14.124\n",
      "\n",
      "scheduler node: 3.15.27.177:8786\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "[ worker 172.26.4.115 ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_worker 3.15.27.177:8786 --nthreads 1 --nprocs 4 --host 172.26.4.115 --memory-limit auto\n",
      "[ worker 172.26.14.124 ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_worker 3.15.27.177:8786 --nthreads 1 --nprocs 4 --host 172.26.14.124 --memory-limit auto\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_scheduler --port 8786\n",
      "[ worker 172.26.11.178 ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_worker 3.15.27.177:8786 --nthreads 1 --nprocs 4 --host 172.26.11.178 --memory-limit auto\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ worker 172.26.4.115 ] : To run a command as administrator (user \"root\"), use \"sudo <command>\".\n",
      "[ worker 172.26.4.115 ] : See \"man sudo_root\" for details.\n",
      "[ worker 172.26.4.115 ] : \n",
      "[ worker 172.26.4.115 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.4.115:32899'\n",
      "[ worker 172.26.4.115 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.4.115:35924'\n",
      "[ worker 172.26.4.115 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.4.115:46463'\n",
      "[ worker 172.26.4.115 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.4.115:33402'\n",
      "[ worker 172.26.14.124 ] : To run a command as administrator (user \"root\"), use \"sudo <command>\".\n",
      "[ worker 172.26.14.124 ] : See \"man sudo_root\" for details.\n",
      "[ worker 172.26.14.124 ] : \n",
      "[ worker 172.26.14.124 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.14.124:34801'\n",
      "[ worker 172.26.14.124 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.14.124:46114'\n",
      "[ worker 172.26.14.124 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.14.124:41475'\n",
      "[ worker 172.26.14.124 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.14.124:32820'\n",
      "[ worker 172.26.11.178 ] : To run a command as administrator (user \"root\"), use \"sudo <command>\".\n",
      "[ worker 172.26.11.178 ] : See \"man sudo_root\" for details.\n",
      "[ worker 172.26.11.178 ] : \n",
      "[ worker 172.26.11.178 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.11.178:40216'\n",
      "[ worker 172.26.11.178 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.11.178:42177'\n",
      "[ worker 172.26.11.178 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.11.178:45844'\n",
      "[ worker 172.26.11.178 ] : distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.11.178:44315'\n",
      "[ worker 172.26.11.178 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-0wa92809', purging\n",
      "[ worker 172.26.11.178 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-498mcd9k', purging\n",
      "[ worker 172.26.11.178 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-4phk72sq', purging\n",
      "[ worker 172.26.11.178 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-6z72_bdy', purging\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-87y7ogfi\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Clear task state\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO -   Scheduler at:   tcp://172.26.1.240:8786\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO -   dashboard at:                     :8787\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.11.178:33330', name: tcp://172.26.11.178:33330, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.11.178:33330\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.11.178:36414', name: tcp://172.26.11.178:36414, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.11.178:36414\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.11.178:39797', name: tcp://172.26.11.178:39797, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.11.178:39797\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.11.178:33354', name: tcp://172.26.11.178:33354, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.11.178:33354\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.4.115 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-5nkn5k1_', purging\n",
      "[ worker 172.26.4.115 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-th7xh8oe', purging\n",
      "[ worker 172.26.4.115 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-qoh_dky_', purging\n",
      "[ worker 172.26.4.115 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-nszrirdi', purging\n",
      "[ worker 172.26.14.124 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-vczfyo5p', purging\n",
      "[ worker 172.26.14.124 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-l2hfliys', purging\n",
      "[ worker 172.26.14.124 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-rfmqu1o3', purging\n",
      "[ worker 172.26.14.124 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/dask-worker-space/worker-etdp_0v7', purging\n",
      "[ worker 172.26.11.178 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.11.178 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.11.178 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.11.178 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -       Start worker at:  tcp://172.26.11.178:36414\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -       Start worker at:  tcp://172.26.11.178:33330\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -          Listening to:  tcp://172.26.11.178:33330\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -          dashboard at:        172.26.11.178:37138\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -          Listening to:  tcp://172.26.11.178:36414\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -                Memory:                    4.21 GB\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-mom0fwsm\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -          dashboard at:        172.26.11.178:33155\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -                Memory:                    4.21 GB\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-lr5cxs0l\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -       Start worker at:  tcp://172.26.11.178:39797\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -          Listening to:  tcp://172.26.11.178:39797\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -          dashboard at:        172.26.11.178:32989\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -       Start worker at:  tcp://172.26.11.178:33354\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -          Listening to:  tcp://172.26.11.178:33354\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -          dashboard at:        172.26.11.178:39859\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -                Memory:                    4.21 GB\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -                Memory:                    4.21 GB\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-ukrhf_yt\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-4auhdhyy\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.11.178 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.11.178 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.11.178 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.14.124 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -       Start worker at:  tcp://172.26.14.124:34104\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -          Listening to:  tcp://172.26.14.124:34104\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -          dashboard at:        172.26.14.124:44253\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -                Memory:                    4.19 GB\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-qzurxp6_\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.14.124 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -       Start worker at:  tcp://172.26.14.124:35903\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -          Listening to:  tcp://172.26.14.124:35903\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -          dashboard at:        172.26.14.124:37972\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -                Memory:                    4.19 GB\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-4cu68pjf\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -       Start worker at:  tcp://172.26.14.124:34487\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -          Listening to:  tcp://172.26.14.124:34487\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -          dashboard at:        172.26.14.124:40111\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -                Memory:                    4.19 GB\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-3kz3z8js\n",
      "[ worker 172.26.14.124 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -       Start worker at:  tcp://172.26.14.124:43565\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -          Listening to:  tcp://172.26.14.124:43565\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -          dashboard at:        172.26.14.124:41865\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -                Memory:                    4.19 GB\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-evke9s7h\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.14.124 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.14.124 ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.14.124:34104', name: tcp://172.26.14.124:34104, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.14.124:34104\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.14.124:35903', name: tcp://172.26.14.124:35903, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.14.124:35903\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.14.124:34487', name: tcp://172.26.14.124:34487, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.14.124:34487\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.14.124:43565', name: tcp://172.26.14.124:43565, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.14.124:43565\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.4.115:35822', name: tcp://172.26.4.115:35822, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.4.115:35822\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.4.115:42557', name: tcp://172.26.4.115:42557, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.4.115:42557\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.4.115:41346', name: tcp://172.26.4.115:41346, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.4.115:41346\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Register worker <Worker 'tcp://172.26.4.115:36344', name: tcp://172.26.4.115:36344, memory: 0, processing: 0>\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.26.4.115:36344\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.4.115 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.4.115 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.4.115 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -       Start worker at:   tcp://172.26.4.115:42557\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -          Listening to:   tcp://172.26.4.115:42557\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -          dashboard at:         172.26.4.115:43764\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -                Memory:                    4.19 GB\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-hu2jr18f\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -       Start worker at:   tcp://172.26.4.115:41346\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -          Listening to:   tcp://172.26.4.115:41346\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -          dashboard at:         172.26.4.115:34523\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -                Memory:                    4.19 GB\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-jpvkw6kr\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -       Start worker at:   tcp://172.26.4.115:35822\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -          Listening to:   tcp://172.26.4.115:35822\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -          dashboard at:         172.26.4.115:46405\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -                Memory:                    4.19 GB\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-sspt05vm\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -       Start worker at:   tcp://172.26.4.115:36344\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -          Listening to:   tcp://172.26.4.115:36344\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -          dashboard at:         172.26.4.115:38582\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - Waiting to connect to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -               Threads:                          1\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -                Memory:                    4.19 GB\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/dask-worker-space/worker-1vz5i3c_\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO -         Registered to:     tcp://3.15.27.177:8786\n",
      "[ worker 172.26.4.115 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.26.4.115 ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Client-a3dc64a2-9148-11ea-a169-7f7739b8b6ae\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Remove client Client-a3dc64a2-9148-11ea-a169-7f7739b8b6ae\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Close client connection: Client-a3dc64a2-9148-11ea-a169-7f7739b8b6ae\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Client-9eaa18b4-9151-11ea-957f-5334b20f1229\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Client-0fc364a6-915a-11ea-9695-fd43e4ca0df4\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Remove client Client-9eaa18b4-9151-11ea-957f-5334b20f1229\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Remove client Client-9eaa18b4-9151-11ea-957f-5334b20f1229\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Close client connection: Client-9eaa18b4-9151-11ea-957f-5334b20f1229\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Client-e36292d0-915c-11ea-96ba-21b0a06daf6b\n",
      "[ \u001b[1mscheduler 3.15.27.177:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n"
     ]
    }
   ],
   "source": [
    "!dask-ssh \\\n",
    "    --scheduler 3.15.27.177 \\\n",
    "    --nprocs 4 \\\n",
    "    --nthreads 1 \\\n",
    "    --ssh-username ubuntu \\\n",
    "    --ssh-private-key ~/.ssh/authorized_keys \\\n",
    "    --hostfile ~/list_of_server.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
